# llm_evaluate
Lightweight evaluation framework for large language model outputs using BLEU, ROUGE, and BERTScore. Loads reference and generated texts, computes similarity metrics to understand how different metrics are used
